[
  {
    "query_id": 1,
    "query": "Fresher Python Software Engineer\nfresher python software engineer company description kms technology is a strategic engineering company helping businesses turn bold ideas into high impact solutions faster founded in 2009 as a u s based services company we ve grown into a global organization with locations in the us vietnam and mexico kms is trusted globally for the quality of our engineering and consulting services we bring deep expertise in product development and quality assurance ai native engineering and delivery excellence to every engagement our mission is to help customers build what s next accelerating innovation crafting brilliant solutions and creating real world impact at kms we believe sustainable growth is built on the success of our clients and employees and in making a lasting contribution to our communities within 3 main business sectors enterprise software development services leverage software domain expertise to help clients make better business decisions in technology platforms increase speed to market and gain critical development support through innovative technology solutions healthcare technology solutions build transformative next gen technologies to solve healthcare s most challenging problems providing innovative tools and expertise to providers payers life sciences and medical technology vendors banking financial services insurance bfsi technology solutions empower bfsi businesses to embrace the digital finance revolution and expedite clients journey towards complete digitalization technology consulting data analytics software development and software quality job description your key responsibilities participate in all software development activities following scrum process contribute to the design and implementation of software features or subsystems using python web frameworks such as django or flask write high quality code to implement software features or fix bugs perform unit testing documentation and all other activities defined in definition of done before passing source code to testing team communicate and report internally or directly to client on status or result of work qualifications your key qualifications general requirements 4th year student or recent graduate with a bachelor s degree in information technology computer science software engineering or a related field with less than one 01 year of experience strong it background with a gpa of 7 5 please attach transcripts when submitting your cv upper intermediate or higher english proficiency both written and verbal minimum 3 month internship experience in software engineering is required strong self learning ability with a proactive growth oriented mindset excellent analytical and problem solving skills ability to work independently and collaborate effectively in a team technical requirements passion for back end and web application development using python possess strong foundation of oop data structures and algorithms familiarity with one or more python web frameworks such as django or flask understanding of restful api development and integration basic knowledge of html css and javascript for front end collaboration familiarity with sql and relational databases e g mysql postgresql basic knowledge of unit testing and debugging techniques familiarity with source control tools such as git understanding of software development best practices including code maintainability and scalability hands on experience through university projects or internship assignments related to web development additional information perks you ll enjoy working in one of the best places to work in vietnam building large scale global software products working growing with passionate talented team diverse careers opportunities with software outsourcing software product development it solutions consulting attractive salary and benefits performance appraisals every year onsite opportunities short term and long term assignments in north america u s canada europe asia flexible working time various training on hot trend technologies best practices and soft skills premium healthcare insurance for you and your loved ones company trip big annual year end party every year team building etc fitness sports activities football tennis table tennis badminton yoga etc joining community development activities 1 pledge charity every quarter blood donation public seminars career orientation talks free in house entertainment facilities foosball ping pong gym etc coffee latte cappuccino espresso and snack instant noodles cookies candies etc and much more send your resume including academic transcript to join us and explore other fantastic things data engineer",
    "company": "KMS Technology, Inc.",
    "user_years": 4,
    "result1": "ibm applied software engineering fundamentals specialization",
    "result2": "meta web development fundamentals specialization",
    "result3": "introduction to software quality assurance",
    "result4": "meta back end developer professional certificate",
    "result5": "ibm ai product manager professional certificate",
    "result6": "ibm product manager professional certificate",
    "result7": "akamai customer consulting and support professional certificate",
    "result8": "ibm applied devops engineering professional certificate",
    "result9": "meta full stack developer front end back end from scratch specialization",
    "result10": "ibm javascript backend developer professional certificate",
    "result11": "engineering practices for building quality software",
    "result12": "sap technology consultant professional certificate",
    "result13": "introduction to ethereum blockchain",
    "result14": "ibm full stack software developer professional certificate",
    "result15": "building cloud computing solutions at scale specialization",
    "result16": "ibm back end development professional certificate",
    "result17": "meta database engineer professional certificate",
    "result18": "ibm devops and software engineering professional certificate",
    "result19": "claude code software engineering with generative ai agents",
    "result20": "java developer with java spring boot spring framework professional certificate",
    "_meta": {
      "summary": "Looking for a Fresher Python Software Engineer to join a global engineering company. Responsibilities include software development using Python web frameworks and collaborating in a team environment.",
      "profile": {
        "level": "Beginner",
        "years_exp": 1,
        "skills": [
          "python",
          "django",
          "flask",
          "oop",
          "data structures",
          "algorithms",
          "restful api",
          "html",
          "css",
          "javascript",
          "sql",
          "git"
        ],
        "domain": "software",
        "title": "Fresher Python Software Engineer",
        "summary": "Looking for a Fresher Python Software Engineer to join a global engineering company. Responsibilities include software development using Python web frameworks and collaborating in a team environment.",
        "user_years": 4
      },
      "time": "2.62s"
    }
  },
  {
    "query_id": 2,
    "query": "Data Engineer (good EN, Upto $2500)\ndata engineer good en upto 2500 position data engineer location hcmc key responsibilities develop and maintain scalable production grade data pipelines support data modeling and integration across various structured data sources contribute to platform migration efforts toward databricks and big data architecture collaborate with analysts architects and stakeholders to deliver reusable data assets apply and help improve engineering best practices in ci cd and data lifecycle join agile ceremonies standups sprint planning retros etc required skills experience bachelor s degree in it computer science data science or related fields at least 3 years of experience in data engineering with strong sql and rdbms knowledge oracle sql server advanced sql skills for complex queries performance tuning and data manipulation solid programming skills in python for data processing automation and etl experience working with spark pyspark scala spark including building scalable distributed data processing pipelines nice to have experience with databricks including unity catalog is a plus familiarity with azure aws or gcp cloud platforms understanding of data modeling integration patterns and pipeline orchestration good english communication and teamwork skills ability to work cross functionally benefits fpt care health insurance is provided by petrolimex pjico and is exclusive for fpt employees annual summer vacation follows the company s policy and starts from may every year salary review 1 time per year international dynamic and friendly working environment annual leave and working conditions follow vietnam labor laws other benefits sponsor for studying and taking international certification exams sponsor loan interest policy for fsofter shuttle bus for employees contact ms thu talent acquisition specialist email thuthm1 fpt com tel zalo 052293049 data engineer",
    "company": "FPT Software Innovation",
    "user_years": 1,
    "result1": "spark hadoop and snowflake for data engineering",
    "result2": "advanced data management in azure databricks",
    "result3": "applied python data engineering specialization",
    "result4": "learn sql with databricks",
    "result5": "mastering azure databricks for data engineers specialization",
    "result6": "automation and project implementation in azure databricks",
    "result7": "pyspark in action hands on data processing",
    "result8": "nosql big data and spark foundations specialization",
    "result9": "aws feature engineering data transformation integrity",
    "result10": "pyspark python hands on guide to data processing",
    "result11": "fundamentals of azure databricks",
    "result12": "data engineering pipelines etl hadoop",
    "result13": "aws database specialty certification",
    "result14": "deeplearning ai data engineering professional certificate",
    "result15": "introduction to pyspark",
    "result16": "aws data automation glue lambda integration",
    "result17": "ibm data engineering professional certificate",
    "result18": "spark and python for big data with pyspark specialization",
    "result19": "data engineering capstone project",
    "result20": "pyspark for data science specialization",
    "_meta": {
      "summary": "Data Engineer position in HCMC with responsibilities including developing data pipelines, supporting data modeling, and collaborating with stakeholders. Required skills include SQL, Python, Spark, cloud platforms, and data modeling.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 3,
        "skills": [
          "sql",
          "rdbms",
          "python",
          "etl",
          "spark",
          "pyspark",
          "scala",
          "azure",
          "aws",
          "gcp",
          "data modeling",
          "ci cd"
        ],
        "domain": "data",
        "title": "Data Engineer (good EN, Upto $2500)",
        "summary": "Data Engineer position in HCMC with responsibilities including developing data pipelines, supporting data modeling, and collaborating with stakeholders. Required skills include SQL, Python, Spark, cloud platforms, and data modeling.",
        "user_years": 1
      },
      "time": "1.48s"
    }
  },
  {
    "query_id": 3,
    "query": "Data Engineer (Junior/Middle)\ndata engineer junior middle about the job design build and optimize etl pipelines for efficient data extraction transformation and loading implement and manage scalable data infrastructure leveraging big data technologies such as spark and hadoop mapreduce utilize azure services including storage account azure databricks and ssis to build and maintain cloud based data solutions develop and deploy ssis packages on azure including configuration debugging and troubleshooting ensure data quality and consistency through strong data modeling and data validation practices collaborate with data scientists and analysts to support data mining and machine learning initiatives contribute to continuous improvement of data architecture monitoring and performance tuning support the team with documentation version control and deployment best practices about you bachelor s degree in information technology computer science or a related field from 2 years of experience as a data engineer or in a similar data focused role proficient in sql with strong coding and scripting skills hands on experience with big data technologies e g spark hadoop mapreduce solid understanding of azure cloud services including storage account and azure databricks strong expertise in data modeling data mining and etl implementation supporting incremental data extraction and loading proficient in building deploying and maintaining ssis packages capable of debugging and troubleshooting issues effectively familiar with machine learning deep learning frameworks such as keras tensorflow scikit learn or r strong analytical problem solving and communication skills open minded flexible and capable of multi tasking in a collaborative team oriented environment eager to learn and continuously develop new technical skills why amaris competitive salary and 13th month salary 14 annual leaves per year premium healthcare insurance starting from your probation period project reviews and yearly performance appraisals annual company trips teambuilding activities team lunch dinner events and celebrations sports clubs football yoga badminton etc international team with flexible working time hybrid working tailor made career path technical workshops and training courses mobility opportunities to be on site abroad in our offices in over 60 countries equal opportunity amaris consulting is proud to be an equal opportunity workplace we are committed to promoting diversity within the workforce and creating an inclusive working environment for this purpose we welcome applications from all qualified candidates regardless of gender sexual orientation race ethnicity beliefs age marital status disability or other characteristics data engineer",
    "company": "Amaris Consulting",
    "user_years": 10,
    "result1": "microsoft azure data scientist cloud powered skills professional certificate",
    "result2": "perform data science with azure databricks",
    "result3": "build and operate machine learning solutions with azure",
    "result4": "spark hadoop and snowflake for data engineering",
    "result5": "automation and project implementation in azure databricks",
    "result6": "nosql big data and spark foundations specialization",
    "result7": "applied python data engineering specialization",
    "result8": "fundamentals of azure databricks",
    "result9": "mastering azure databricks for data engineers specialization",
    "result10": "ibm data architect with mysql postgresql cassandra professional certificate",
    "result11": "microsoft cloud support associate professional certificate",
    "result12": "advanced data management in azure databricks",
    "result13": "prep for microsoft azure data engineer associate cert dp 203",
    "result14": "mlops platforms amazon sagemaker and azure ml",
    "result15": "microsoft azure machine learning for data scientists",
    "result16": "data engineering pipelines etl hadoop",
    "result17": "microsoft azure security engineer associate az 500 professional certificate",
    "result18": "prepare for dp 100 data science on microsoft azure exam",
    "result19": "microsoft azure data fundamentals dp 900 exam prep specialization",
    "result20": "create machine learning models in microsoft azure",
    "_meta": {
      "summary": "Seeking a Junior/Middle Data Engineer to design, build, and optimize ETL pipelines using big data technologies and Azure services. Collaborate with data scientists and analysts to support data mining and machine learning initiatives.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 2,
        "skills": [
          "sql",
          "coding",
          "scripting",
          "big data",
          "azure",
          "data modeling",
          "data mining",
          "etl",
          "ssis",
          "machine learning",
          "deep learning",
          "communication"
        ],
        "domain": "data",
        "title": "Data Engineer (Junior/Middle)",
        "summary": "Seeking a Junior/Middle Data Engineer to design, build, and optimize ETL pipelines using big data technologies and Azure services. Collaborate with data scientists and analysts to support data mining and machine learning initiatives.",
        "user_years": 10
      },
      "time": "1.81s"
    }
  },
  {
    "query_id": 4,
    "query": "Data Engineer, Specialist\ndata engineer specialist report to manager data engineer location ho chi minh function customer and information technology department information technology type individual contributor the opportunity we are currently looking for data engineer specialist who is responsible for developing and maintaining data pipelines infrastructure and systems that support advanced analytics initiatives across various departments and support data integration within the data warehouse platform as enterprise golden source roles and responsibilities develop and implement data pipelines etl processes and set up routines for data from various data sources optimize the data processing and query performance to ensure scalable and efficient data operations implement data quality controls data governance policies and securities requirement to safeguard sensitive insurance data collaborate with data scientist data analysts and other business stakeholders to understand data needs develop technical and training manuals and comply to other company data life cycle standards stay up to date with emerging technologies trends and best practice in data engineers to drive continuous improvement and innovation job requirements education experience education bsc degree in computer science data engineering information systems mathematics or relevant fields experience 3 5 years of experience as a data engineer or similar role within the life insurance industry or other relevant financial services sector technical skill experience with data warehouse databrick spark experience with business intelligence power bi expert level sql sql server sql databrick experience in programming language python spark experience with git source control experience with building data model special on insurance domain hands on experience of working with data projects that have a complete ci cd system experience with etl tool azure data factory airflow soft skill ability to influence both technical and business peers and stakeholders lead by example jump on the tools when required to support the team good communication skills with the ability to convey complex technical concepts in clear and concise language for various audiences english communication is required demonstrated problem solving skills and a results oriented mindset data engineer",
    "company": "AIA Vietnam",
    "user_years": 6,
    "result1": "deeplearning ai data engineering professional certificate",
    "result2": "data engineering pipelines etl hadoop",
    "result3": "data engineering capstone project",
    "result4": "ibm relational database administrator with genai professional certificate",
    "result5": "spark hadoop and snowflake for data engineering",
    "result6": "generative ai elevate your data engineering career",
    "result7": "google business intelligence professional certificate",
    "result8": "aws data automation glue lambda integration",
    "result9": "automation and project implementation in azure databricks",
    "result10": "aws feature engineering data transformation integrity",
    "result11": "applied python data engineering specialization",
    "result12": "advanced data management in azure databricks",
    "result13": "data science methods for quality improvement specialization",
    "result14": "relational database administration capstone project",
    "result15": "python project for data engineering",
    "result16": "prep for microsoft azure data engineer associate cert dp 203",
    "result17": "enterprise data integration governance and architecture specialization",
    "result18": "data warehouse fundamentals",
    "result19": "microsoft azure security engineer associate az 500 professional certificate",
    "result20": "mastering azure databricks for data engineers specialization",
    "_meta": {
      "summary": "Looking for a Data Engineer Specialist to develop and maintain data pipelines, infrastructure, and systems supporting advanced analytics initiatives. Responsibilities include optimizing data processing, implementing data quality controls, and collaborating with stakeholders.",
      "profile": {
        "level": "Advanced",
        "years_exp": 5,
        "skills": [
          "data warehouse",
          "databrick",
          "sql",
          "python",
          "git",
          "data model",
          "ci cd",
          "etl",
          "azure data factory",
          "airflow",
          "communication",
          "problem solving"
        ],
        "domain": "data",
        "title": "Data Engineer, Specialist",
        "summary": "Looking for a Data Engineer Specialist to develop and maintain data pipelines, infrastructure, and systems supporting advanced analytics initiatives. Responsibilities include optimizing data processing, implementing data quality controls, and collaborating with stakeholders.",
        "user_years": 6
      },
      "time": "1.85s"
    }
  },
  {
    "query_id": 5,
    "query": "Data Engineer\ndata engineer as a data engineer you ll lead initiatives optimizing data flow ensuring quality and implementing security measures job description data engineering design and implement scalable and secure data pipelines for collecting processing and storing data develop and maintain datasets ensuring accuracy completeness and compliance with security standards work closely with data scientists and analysts to understand data needs and implement solutions that meet compliance requirements implement robust data quality checks and validation processes to identify and rectify inconsistencies ensuring data integrity optimize data processing and storage for efficiency cost effectiveness and compliance identify and implement solutions to enhance the performance of data pipelines with a focus on security best practices apply expertise in security practices ensuring the protection of sensitive data job requirements bachelor s degree in computer science information technology or a related field 2 or more years of experience as a data engineer etl developer or similar roles with expertise in etl processes and tools preferably in banking or financial services experience in data modeling data lake and data warehousing strong proficiency in programming languages such as python java or scala strong proficiency in airflow for designing and managing complex workflows and dependencies solid understanding of data analytics and flow analysis for mobile app user interfaces familiarity with database systems e g sql nosql and data integration tools strong analytical and problem solving skills with a detail oriented mindset excellent communication and collaboration skills to work effectively with cross functional teams knowledge of cloud platforms e g aws gcp and related data technologies is a plus knowledge of security practices in the context of data handling familiarity with version control systems e g git and agile software development practices good communication skills ability to explain your findings to business technical stakeholders in an efficient manner be able to manage time effectively deliver high quality work ability to work independently and manage multiple tasks within deadlines possess a proactive mindset positive attitude able to bring in good influences to your teammates stakeholders data engineer",
    "company": "Galaxy FinX",
    "user_years": 8,
    "result1": "data engineering pipelines etl hadoop",
    "result2": "aws data automation glue lambda integration",
    "result3": "deeplearning ai data engineering professional certificate",
    "result4": "enterprise data architecture and operations",
    "result5": "ibm relational database administrator with genai professional certificate",
    "result6": "advanced data management in azure databricks",
    "result7": "spark hadoop and snowflake for data engineering",
    "result8": "generative ai elevate your data engineering career",
    "result9": "distributed query optimization and security",
    "result10": "prep for microsoft azure data engineer associate cert dp 203",
    "result11": "engineering practices for building quality software",
    "result12": "salesforce clm cpq streamlining contract operations",
    "result13": "managing data lakes pipelines with google cloud dataplex",
    "result14": "data engineering with rust",
    "result15": "advanced business analysis elicitation analysis",
    "result16": "aws feature engineering data transformation integrity",
    "result17": "aws data processing and analysis",
    "result18": "aws ml workflows with sagemaker storage security",
    "result19": "protection of information assets",
    "result20": "automation and project implementation in azure databricks",
    "_meta": {
      "summary": "Seeking a Data Engineer to lead initiatives optimizing data flow, ensuring quality, and implementing security measures. Responsibilities include designing and implementing scalable data pipelines, maintaining datasets, and enhancing data processing efficiency.",
      "profile": {
        "level": "Advanced",
        "years_exp": 0,
        "skills": [
          "etl",
          "data modeling",
          "python",
          "java",
          "scala",
          "airflow",
          "data analytics",
          "sql",
          "nosql",
          "data integration",
          "cloud platforms",
          "security practices"
        ],
        "domain": "data",
        "title": "Data Engineer",
        "summary": "Seeking a Data Engineer to lead initiatives optimizing data flow, ensuring quality, and implementing security measures. Responsibilities include designing and implementing scalable data pipelines, maintaining datasets, and enhancing data processing efficiency.",
        "user_years": 8
      },
      "time": "2.37s"
    }
  },
  {
    "query_id": 6,
    "query": "Data Engineer\ndata engineer worldquant develops and deploys systematic financial strategies across a broad range of asset classes and global markets we seek to produce high quality predictive signals alphas through our proprietary research platform to employ financial strategies focused on market inefficiencies our teams work collaboratively to drive the production of alphas and financial strategies the foundation of a balanced global investment platform worldquant is built on a culture that pairs academic sensibility with accountability for results employees are encouraged to think openly about problems balancing intellectualism and practicality excellent ideas come from anyone anywhere employees are encouraged to challenge conventional thinking and possess an attitude of continuous improvement our goal is to hire the best and the brightest we value intellectual horsepower first and foremost and people who demonstrate an outstanding talent there is no roadmap to future success so we need people who can help us build it technologists at worldquant research design code test and deploy firmwide platforms and tooling while working collaboratively with researchers our environment is relaxed yet intellectually driven we seek people who think in code and are motivated by being around like minded people the role we are looking for an experienced data engineer who will help us to build and maintain an ecosystem for processing multiple datasets from different sources both internal and external vital to the firm s investment operations what you ll do creating automated data processing system and monitoring maintaining it integrating multiple data sources and databases into one system developing interfaces and micro services in python enriching company s data by applying nlp and ai models preprocessing and cleansing of semi structured or unstructured data developing efficient algorithms for data processing testing and integrating external apis supporting business analysts team what you ll bring a bachelor master s degree in a technical or quantitative field from top university at least 3 years of experience as a data engineer or software developer excellent programming skills experience with data processing using python experience with building databases experience with containers and kubernetes scripting skills in unix environment shell python fire etc experience with code versioning tools e g git issue tracking tools e g jira debugging skills eye for detail and identifying problems strong problem solving skills and an analytical mindset a passion for working with data what we offer competitive and attractive compensation package with clear career road map where you feel challenged everyday we offer a strong culture of learning and development training courses library speakers share and learn events learn from who sits next to you working in wq you are surrounded by smart and talented people premium health insurance and employee assistance program generous time off policy re creation sabbatical leave based on tenure trade union benefits for staff and family team building activities every month local engagement events monthly team lunch employee clubs football ping pong badminton yoga running ps5 movies etc annual company trip and occasional global conferences opportunity to travel and connect with our global teams happy hour with tea break snacks and meals every day in the office by submitting this application you acknowledge and consent to terms of the worldquant privacy policy the privacy policy offers an explanation of how and why your data will be collected how it will be used and disclosed how it will be retained and secured and what legal rights are associated with that data including the rights of access correction and deletion the policy also describes legal and contractual limitations on these rights the specific rights and obligations of individuals living and working in different areas may vary by jurisdiction copyright 2025 worldquant llc all rights reserved worldquant is an equal opportunity employer and does not discriminate in hiring on the basis of race color creed religion sex sexual orientation or preference age marital status citizenship national origin disability military status genetic predisposition or carrier status or any other protected characteristic as established by applicable law data engineer",
    "company": "WorldQuant",
    "user_years": 10,
    "result1": "python a guided journey from introduction to application specialization",
    "result2": "reducing gun violence in america evidence for change",
    "result3": "european business law understanding the fundamentals",
    "result4": "severe to profound intellectual disability circles of care and education",
    "result5": "meta database engineer professional certificate",
    "result6": "git for beginners with hands on labs",
    "result7": "machine learning for all",
    "result8": "european business law doing business in europe",
    "result9": "git basics for devops",
    "result10": "sustainability and the circular economy",
    "result11": "local economic development",
    "result12": "people soft skills essential for professional success specialization",
    "result13": "python bash and sql essentials for data engineering specialization",
    "result14": "pathway to space specialization",
    "result15": "linux for beginners with hands on labs",
    "result16": "leading teams effectively skills for impactful leadership",
    "result17": "management communication",
    "result18": "global health security solidarity and sustainability through the international health regulations",
    "result19": "introduction to python",
    "result20": "supply chain management a learning perspective",
    "_meta": {
      "summary": "WorldQuant is seeking an experienced Data Engineer to build and maintain a data processing ecosystem for investment operations. The role involves creating automated data processing systems, integrating multiple data sources, and developing interfaces using Python.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 3,
        "skills": [
          "python",
          "data processing",
          "databases",
          "containers",
          "kubernetes",
          "unix",
          "shell scripting",
          "fire",
          "git",
          "jira",
          "debugging",
          "nlp"
        ],
        "domain": "data",
        "title": "Data Engineer",
        "summary": "WorldQuant is seeking an experienced Data Engineer to build and maintain a data processing ecosystem for investment operations. The role involves creating automated data processing systems, integrating multiple data sources, and developing interfaces using Python.",
        "user_years": 10
      },
      "time": "1.90s"
    }
  },
  {
    "query_id": 7,
    "query": "Senior/Lead Data Engineer\nsenior lead data engineer tymex is building some of world s fastest growing digital banks and the data team plays a key role in driving the bank s vision of creating a platform that stimulates economic participation and facilitates broader financial inclusion by implementing creative best in class data and analytic solutions to achieve success in providing quality services and products to our customers and optimising the business as a senior lead data engineer you will contribute to the mission by creating solutions that will directly support informed decision making and innovation by providing clean protected quality and auditable data from various sources into fit for purpose data products in this role you can expect to design develop test deploy and monitor data pipelines in databricks on aws from a wide variety of data sources design develop test deploy and monitor scalable code with pyspark and sql in databricks identify opportunities to improve internal process through code optimisation and automation build data quality dashboards lineage flows and or monitoring tools to utilize the data pipeline providing active monitoring and actionable insight into overall data quality and data governance assist in migrating data from legacy systems onto newly developed solutions follow and lead best practices on all data security retention and privacy policies requirements bachelor s degree 3 years experience of building etl elt pipelines proven competency in solution design development implementation reporting and analysis proficiency in apache spark python and sql languages proficiency in working with text delta parquet json csv and xml data formats working knowledge of spark structured streaming aws infrastructure experience specifically working with s3 solid understanding of git based version control devops and ci cd experience of working on atlassian stack a plus knowledge of common web api frameworks and web services strong teamwork relationship and client management skills and the ability to influence peers and senior management to accomplish team goals willingness to embrace modern technology best practice and ways of work benefits performance bonus up to 2 months 13th month salary pro rata 15 day annual leave 3 day sick leave 1 birthday leave 1 christmas leave meal and parking allowance are covered by the company full benefits and salary rank during probation insurances as vietnamese labor law and premium health care for you and your family without seniority compulsory smart goals and clear career opportunities technical seminar conference and career talk we focus on your development values driven international working environment and agile culture overseas travel opportunities for training and working related internal hackathons and company s events team building coffee run blue card work life balance 40 hr per week from mon to fri data engineer",
    "company": "TymeX",
    "user_years": 7,
    "result1": "automation and project implementation in azure databricks",
    "result2": "aws data automation glue lambda integration",
    "result3": "microsoft full stack developer professional certificate",
    "result4": "ibm data engineering professional certificate",
    "result5": "prep for microsoft azure data engineer associate cert dp 203",
    "result6": "mastering azure databricks for data engineers specialization",
    "result7": "spark hadoop and snowflake for data engineering",
    "result8": "advanced data management in azure databricks",
    "result9": "aws cloud technology consultant professional certificate",
    "result10": "deeplearning ai data engineering professional certificate",
    "result11": "aws database specialty certification",
    "result12": "people soft skills essential for professional success specialization",
    "result13": "nosql big data and spark foundations specialization",
    "result14": "ibm data architect with mysql postgresql cassandra professional certificate",
    "result15": "prepare for dp 100 data science on microsoft azure exam",
    "result16": "advanced data engineering with snowflake",
    "result17": "perform data science with azure databricks",
    "result18": "bi foundations with sql etl and data warehousing specialization",
    "result19": "devops on aws and project management",
    "result20": "aws certified data engineer associate specialization",
    "_meta": {
      "summary": "Senior/Lead Data Engineer at Tymex, responsible for building data pipelines in Databricks on AWS, implementing data solutions, and ensuring data quality. Offers benefits like performance bonus, annual leave, and career development opportunities.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 3,
        "skills": [
          "apache spark",
          "python",
          "sql",
          "etl",
          "databricks",
          "aws",
          "git",
          "devops",
          "ci cd",
          "data quality",
          "data governance",
          "data pipelines"
        ],
        "domain": "data",
        "title": "Senior/Lead Data Engineer",
        "summary": "Senior/Lead Data Engineer at Tymex, responsible for building data pipelines in Databricks on AWS, implementing data solutions, and ensuring data quality. Offers benefits like performance bonus, annual leave, and career development opportunities.",
        "user_years": 7
      },
      "time": "2.29s"
    }
  },
  {
    "query_id": 8,
    "query": "Data Engineer (Open for Mid/Senior)\ndata engineer open for mid senior according to decree no 13 2023 nd cp on protecting personal data pdp home credit vietnam would apply personal data processing agreement with all candidates to ensure compliance with the decree by submitting this application to home credit vietnam finance company limited through linkedin you agree to allow home credit to proceed your provided information in accordance with personal data processing agreement that you have read fully understood and agreed to the entire content at link https career homecredit vn en article id 217 job description collaboration in virtual domain aligned team work closely with the product owner data scientists analysts and other colleagues in agile way towards shared product goals ensure and promote proper data model design and feasibility of data products including ai ml model training serving continuous improvement technical excellence and accountability follow and enrich data product building blocks and code templates review and approve changes from contributors follow select and apply the latest technologies and best practices in data integration and ai ml aligned with context of our company automated testing code quality and documentation implement and maintain quality standards for data products well documented reusable scalable performing dry ensure regular testing and validation are implemented as vital part of automated ci cd monitor and improve the performance and efficiency of data flows key requirements strong experience in data engineer skills in spark kafka python dbt iceberg airflow or cloud technologies aws gcp azure demonstrated experience designing dimensional data model effective algorithms to process data software engineering principles proficiency in sql and python good english communication good stakeholder management skills nice to have finance banking ecommerce domain knowledge especially in risk antifraud crm models microservice architecture with docker and kubernetes development experience compensation benefits 13th salary fixed and kpi bonus premium health care 24 7 accidental insurance 100 social insurance meal phone allowance yearly medical checkup 15 18 annual leaves professional and transparent working environment apply latest financial technology in the world data engineer",
    "company": "Home Credit Vietnam",
    "user_years": 3,
    "result1": "deeplearning ai data engineering professional certificate",
    "result2": "operationalizing ml models mlops for scalable ai",
    "result3": "ibm applied devops engineering professional certificate",
    "result4": "spark hadoop and snowflake for data engineering",
    "result5": "engineering practices for building quality software",
    "result6": "ibm machine learning with python scikit learn professional certificate",
    "result7": "python project for data engineering",
    "result8": "aws model training optimization deployment",
    "result9": "ai workflow ai in production",
    "result10": "microsoft azure data scientist cloud powered skills professional certificate",
    "result11": "automation and project implementation in azure databricks",
    "result12": "ibm rag and agentic ai build next gen ai assistants professional certificate",
    "result13": "aws feature engineering data transformation integrity",
    "result14": "qa process optimization agile automated testing",
    "result15": "microsoft azure for ai and machine learning",
    "result16": "building cloud computing solutions at scale specialization",
    "result17": "prepare for dp 100 data science on microsoft azure exam",
    "result18": "llm engineering with rag optimizing ai solutions",
    "result19": "machine learning on google cloud specialization",
    "result20": "preparing for google cloud certification cloud engineer professional certificate",
    "_meta": {
      "summary": "Seeking a Data Engineer for a mid/senior position at Home Credit Vietnam. Responsibilities include collaborating in a virtual domain, designing data models, implementing AI/ML models, and ensuring technical excellence.",
      "profile": {
        "level": "Advanced",
        "years_exp": 0,
        "skills": [
          "spark",
          "kafka",
          "python",
          "dbt",
          "airflow",
          "aws",
          "gcp",
          "azure",
          "sql",
          "data modeling",
          "software engineering",
          "docker"
        ],
        "domain": "data",
        "title": "Data Engineer (Open for Mid/Senior)",
        "summary": "Seeking a Data Engineer for a mid/senior position at Home Credit Vietnam. Responsibilities include collaborating in a virtual domain, designing data models, implementing AI/ML models, and ensuring technical excellence.",
        "user_years": 3
      },
      "time": "2.42s"
    }
  },
  {
    "query_id": 9,
    "query": "Data Engineer (Middle/Senior)\ndata engineer middle senior about the job design implement and maintain scalable reliable and efficient data pipelines to extract transform and load etl data from various sources develop and manage data architecture solutions ensuring systems are optimized for performance and scalability work closely with data scientists analysts and other stakeholders to understand data requirements and deliver solutions that meet business needs integrate data from diverse sources including apis databases and third party platforms ensuring data quality and consistency monitor and optimize data workflows and infrastructure to enhance performance and reduce latency stay updated with emerging technologies and evaluate their potential to enhance the data engineering function contribute to data modeling efforts to enhance data accessibility and usability assist in the integration of ssis for data workflows when necessary about you bachelor s degree in computer science information technology or a related field from 4 years of hands on experience as a data engineer or in a similar role strong programming skills in python spark pyspark strong sql skills and experience with relational databases e g mysql postgresql familiarity with cloud platforms such as aws azure expertise in data modeling etl development and data warehouse design good understanding of building data pipelines using an etl tool like ssis experience with big data tools and frameworks such as apache spark hadoop or kafka excellent problem solving skills and attention to detail strong communication and collaboration skills why amaris 13th month salary 14 annual leaves per year premium healthcare insurance starting from your probation period project reviews and yearly performance appraisals annual company trips teambuilding activities team lunch dinner events and celebrations sports clubs football yoga badminton etc international team with flexible working time hybrid working tailor made career path technical workshops and training courses mobility opportunities to be on site abroad in our offices in over 60 countries equal opportunity amaris consulting is proud to be an equal opportunity workplace we are committed to promoting diversity within the workforce and creating an inclusive working environment for this purpose we welcome applications from all qualified candidates regardless of gender sexual orientation race ethnicity beliefs age marital status disability or other characteristics data engineer",
    "company": "Amaris Consulting",
    "user_years": 5,
    "result1": "ibm data architect with mysql postgresql cassandra professional certificate",
    "result2": "ibm data engineering professional certificate",
    "result3": "data engineering pipelines etl hadoop",
    "result4": "data engineering capstone project",
    "result5": "ibm data warehouse engineer professional certificate",
    "result6": "nosql big data and spark foundations specialization",
    "result7": "ibm relational database administrator with genai professional certificate",
    "result8": "aws data automation glue lambda integration",
    "result9": "introduction to data engineering",
    "result10": "bi foundations with sql etl and data warehousing specialization",
    "result11": "deeplearning ai data engineering professional certificate",
    "result12": "spark hadoop and snowflake for data engineering",
    "result13": "applied python data engineering specialization",
    "result14": "prep for microsoft azure data engineer associate cert dp 203",
    "result15": "generative ai elevate your data engineering career",
    "result16": "introduction to pyspark",
    "result17": "aws data processing and analysis",
    "result18": "data engineering foundations specialization",
    "result19": "python project for data engineering",
    "result20": "relational database administration capstone project",
    "_meta": {
      "summary": "Seeking a Middle/Senior Data Engineer to design, implement, and maintain scalable data pipelines. Must have strong skills in Python, Spark, SQL, cloud platforms, ETL development, and data modeling.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 4,
        "skills": [
          "python",
          "spark",
          "sql",
          "cloud platforms",
          "etl development",
          "data modeling",
          "big data tools",
          "apache spark",
          "hadoop",
          "kafka",
          "ssis",
          "relational databases"
        ],
        "domain": "data",
        "title": "Data Engineer (Middle/Senior)",
        "summary": "Seeking a Middle/Senior Data Engineer to design, implement, and maintain scalable data pipelines. Must have strong skills in Python, Spark, SQL, cloud platforms, ETL development, and data modeling.",
        "user_years": 5
      },
      "time": "2.00s"
    }
  },
  {
    "query_id": 10,
    "query": "Data Engineer\ndata engineer about us temus is a vision to value company based in singapore we have strategic consultants software engineers human centric designers and a cutting edge ai and data team we help our clients succeed in their digital transformation projects focusing on sustainability health and personal development ambitious in the public and private sectors we have a growing team in vietnam to support these meaningful initiatives apply if you meet all of these must have requirements professional experience at least 3 years of experience in data analytic engineering technical skills advanced sql and python proficiency with cloud data platform experience snowflake preferred soft skills excellent english communication with proven client solution delivery team skills remote cross functional collaboration with proven delivery track record during your working week you will collaborate within a cross functional team to gather requirements ensure seamless data flows and deliver impactful solutions implement a new gold data layer that will expose data as a product to the end users bring business logic from other bi systems i e qlik sense into snowflake to ensure streamlined and efficient access for users reducing dependency on manual aggregation deploy and maintain data quality practices ensuring product integrity and consistency integrate ai products to create intelligent data solutions that enhance user experience receive mentorship from your manager to foster your professional growth your profile required qualities proven track record in data engineering fundamentals strong focus on code quality and system reliability data modelling and warehouse design expertise excellent problem solving and analytical skills self motivated with ability to work independently desired experience snowflake and qlik sense expertise financial services industry knowledge ci cd and version control practices familiar or relevant experience with llms technology application in data engineering personal attributes passionate about data and automation with a growth mindset proactive team player who takes initiative to solve problems what we offer join a team of 50 skilled ai data engineers structured learning and growth opportunities flexible work from home arrangement competitive compensation package voice of your future project lead bram desoete we prioritize good engineering practices above fast and loose types of work you will work with quality and precision on projects that will impact to singapore society be ready to embrace newer approaches like llm s to speed up our combined delivery productivity equal opportunities temus welcomes everyone we do not treat people differently because of their race religion age disability gender or any other reason we value the diversity of our team and work hard to keep it that way data engineer",
    "company": "Temus",
    "user_years": 7,
    "result1": "people soft skills essential for professional success specialization",
    "result2": "advanced data engineering with snowflake",
    "result3": "engineering practices for building quality software",
    "result4": "ai product management specialization",
    "result5": "construction management project delivery methods contracts",
    "result6": "sustainability and the circular economy",
    "result7": "remote team management specialization",
    "result8": "python a guided journey from introduction to application specialization",
    "result9": "collaborate effectively for professional success",
    "result10": "genai for software developers specialization",
    "result11": "qa process optimization agile automated testing",
    "result12": "snowflake data engineering professional certificate",
    "result13": "introduction to multinational and cross cultural teams",
    "result14": "git basics for devops",
    "result15": "git for beginners with hands on labs",
    "result16": "machine learning for all",
    "result17": "introduction to data visualization in qlik sense",
    "result18": "connected leadership building collaborative teams",
    "result19": "communication strategies for a virtual age",
    "result20": "key technologies for business specialization",
    "_meta": {
      "summary": "Temus, a vision to value company based in Singapore, is seeking a Data Engineer with at least 3 years of experience in data analytic engineering and proficiency in SQL, Python, and cloud data platforms.",
      "profile": {
        "level": "Intermediate",
        "years_exp": 3,
        "skills": [
          "sql",
          "python",
          "cloud data platform",
          "snowflake",
          "data modeling",
          "data warehouse design",
          "ci cd",
          "llms technology",
          "data quality practices",
          "ai products",
          "problem solving",
          "analytical skills"
        ],
        "domain": "data",
        "title": "Data Engineer",
        "summary": "Temus, a vision to value company based in Singapore, is seeking a Data Engineer with at least 3 years of experience in data analytic engineering and proficiency in SQL, Python, and cloud data platforms.",
        "user_years": 7
      },
      "time": "2.13s"
    }
  }
]